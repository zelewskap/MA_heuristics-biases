{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "yNWbHOo7kEiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwCx-nF1mPQi",
        "outputId": "88e64381-1363-45ed-e1f8-8963bbae8962",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Collecting openai\n",
            "  Downloading openai-1.57.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Downloading openai-1.57.1-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-1.57.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ],
      "metadata": {
        "id": "M4yzcox5JECG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "ous5r7j9Jn8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai.types.chat import ChatCompletion\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5j3C68almcv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API key"
      ],
      "metadata": {
        "id": "cqY5-NMQkJ2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = epi_key"
      ],
      "metadata": {
        "id": "A4n5KQJ0m5DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=api_key,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-4o-mini\",\n",
        ")"
      ],
      "metadata": {
        "id": "Hcp0bMt2mINW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zPGAUx-mo6O",
        "outputId": "d313df3a-bb5e-4a20-8753-140c942c0c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-AdHLDKwdhAgoLQ2wffHYKBSZRMb8S', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test. How can I assist you further?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1733924815, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_bba3c8e70b', usage=CompletionUsage(completion_tokens=12, prompt_tokens=12, total_tokens=24, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing definitions for final prompt design"
      ],
      "metadata": {
        "id": "HsclCr3ZY88k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def definition(text):\n",
        "    # Make the API call\n",
        "    definition = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": \"You are a scientific analytic tool designed to identify affect heuristic, availability heuristic, representativeness heuristic, confirmation bias and all-or-nothing thinking in text.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Please provide a definition of '{text}' in two sentences.\",\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Extract the sentiment from the response\n",
        "    result = definition.choices[0].message.content.strip()\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "bias = \"all-or-nothing thinking\"\n",
        "result = definition(bias)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44E5zWFMZA9k",
        "outputId": "c2a8a9de-acad-44cf-f2a3-f2f675231947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All-or-nothing thinking is a cognitive distortion that involves viewing situations in black-and-white terms, with no middle ground. This type of thinking often leads to extreme evaluations of experiences, where outcomes are seen as completely successful or entirely failed, disregarding any nuances or complexities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic analysis"
      ],
      "metadata": {
        "id": "6wP9i4l_hHrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_messages(text):\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"\"content\": \"You are a text annotation tool designed to identify and quantify biases and heuristics in a given text. Your role is to evaluate each statement and assign probabilities (0 to 1) for the presence of the following biases or heuristics : affect heuristic, availability heuristic, representativeness heuristic, confirmation bias, and all-or-nothing thinking. The given text can have more than 1 bias or heuristic. If the text does not include any heuristic or bias, or if it is ambiguous, respond with 'No_bias' or 'Unclear', respectively.\n",
        "            Definitions:\n",
        "\n",
        "            - Affect Heuristic: When one's emotions or feelings influence their judgments and decisions, with positive emotions increasing perceived benefits and reducing risks, and negative emotions doing the opposite\n",
        "\n",
        "            - Availability Heuristic: When one overestimates the probability of events they can easily recall or have recently experienced, and underestimates the likelihood of less memorable or less frequently encountered events.\n",
        "\n",
        "            - Representativeness Heuristic: When one judges an object or person based on how closely they resemble the typical category member, either assuming they belong to that category or do not belong based on this similarity.\n",
        "\n",
        "            - Confirmation Bias: When one seeks out or favors information supporting their beliefs while disregarding or ignoring evidence that contradicts them.\n",
        "\n",
        "            - All-or-Nothing Thinking: When one views situations in extreme, black-and-white terms, without recognizing any middle ground or nuance.\n",
        "\n",
        "\n",
        "            Instructions:\n",
        "\n",
        "            1. Carefully analyze the main idea and emotional tone of the given text.\n",
        "\n",
        "            2. Assign a probability (0-1) using three decimal places for each bias, reflecting how likely the bias is present in the text.\n",
        "\n",
        "            3. Respond with a flat string containing probabilities for each bias in this format:\n",
        "\n",
        "            \"affect_h\": 0.336, \"availability_h\": 0.284, \"representativeness_h\": 0.207, \"confirmation_b\": 0.083, \"all_or_nothing\": 0.164, \"no_bias\": 0.07, \"unclear\": 0.02.\n",
        "\n",
        "\n",
        "            Consider the broader context, definitions, and cues such as:\n",
        "\n",
        "            Affect Heuristic: Emotional language.\n",
        "\n",
        "            Availability Heuristic: References to recent or vivid events.\n",
        "\n",
        "            Representativeness Heuristic: Stereotypes or generalizations.\n",
        "\n",
        "            Confirmation Bias: Selective use of supporting information.\n",
        "\n",
        "            All-or-Nothing Thinking: Extreme terms like \"always,\" \"never,\" \"only.\" Determine the probabilities based on definitions.\"\"\"\n",
        "                    },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Analyze the following text and return probabilities for each heuristic or bias: '{text}'\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"\"\"Based on the analysis, does the speaker use heuristics or cognitive biases? Assign a probability (0-1) for each bias, reflecting how likely the bias is present in the text based on the definitions in the format: affect_h\": 0.732, \"availability_h\": 0.312, \"representativeness_h\": 0.008, \"confirmation_b\": 0.578, \"all_or_nothing\": 0.164, \"no_bias\": 0.07, \"unclear\": 0.02\"\"\"\n",
        "        }\n",
        "    ]"
      ],
      "metadata": {
        "id": "DwR26h2NYWtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentences_batch(sentences, batch_size):\n",
        "    results = []\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        batch = sentences[i:i + batch_size]\n",
        "        batch_messages = [create_messages(sentence) for sentence in batch]\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=sum(batch_messages, []),\n",
        "                temperature=0.2\n",
        "                #max_tokens=100\n",
        "            )\n",
        "\n",
        "            for choice in response.choices:\n",
        "                pathos = choice.message.content.strip().lower()\n",
        "                results.append(pathos)\n",
        "        except openai.error.RateLimitError as e:\n",
        "            print(f\"Rate limit reached: {e}. Waiting 60 seconds.\")\n",
        "            time.sleep(300)\n",
        "            continue\n",
        "        except openai.error.OpenAIError as e:\n",
        "            print(f\"Failed to get response from OpenAI: {e}\")\n",
        "            results.extend([None] * len(batch))\n",
        "            continue\n",
        "    return results"
      ],
      "metadata": {
        "id": "LP-18aNfbS1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process a single file\n",
        "def process_file(input_file, output_file, checkpoint_file, batch_size):\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\"Skipping {input_file} as it is already processed.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_excel(input_file)\n",
        "    start_index = 0\n",
        "\n",
        "    # Check if checkpoint exists\n",
        "    if os.path.exists(checkpoint_file):\n",
        "        checkpoint_df = pd.read_pickle(checkpoint_file)\n",
        "        start_index = checkpoint_df.shape[0]\n",
        "        print(f\"Resuming {input_file} from sentence {start_index}.\")\n",
        "        df = df[start_index:]\n",
        "\n",
        "    # Analyze sentences\n",
        "    for index, row in enumerate(df.itertuples(), start=start_index):\n",
        "        pathos_results = analyze_sentences_batch([row.Text], batch_size)\n",
        "        df.at[index, 'bias'] = pathos_results[0] if pathos_results else None\n",
        "\n",
        "        if index % 10 == 0:\n",
        "            # Save checkpoint\n",
        "            checkpoint_df = df.iloc[:index + 1]\n",
        "            checkpoint_df.to_pickle(checkpoint_file)\n",
        "            print(f\"Checkpoint saved at sentence {index} for {input_file}.\")\n",
        "\n",
        "    # Save final results\n",
        "    df.to_excel(output_file, index=False)\n",
        "    print(f\"Analysis completed for {input_file} and saved as {output_file}\")\n",
        "\n",
        "    # Remove checkpoint file\n",
        "    if os.path.exists(checkpoint_file):\n",
        "        os.remove(checkpoint_file)"
      ],
      "metadata": {
        "id": "JAGewnISba3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/\"\n",
        "input_file = dir + 'Zgodność_s2_twitter_AI.xlsx'\n",
        "output_file = dir + 'Twitter_AI_with_unclear_output.xlsx'\n",
        "checkpoint_file = dir + 'Twitter_AI_checkpoint.pkl'\n",
        "\n",
        "batch_size = 1093\n",
        "\n",
        "# Process the file\n",
        "process_file(input_file, output_file, checkpoint_file, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUSCMrBZbgow",
        "outputId": "9e7518f6-699c-40a3-bba7-d989e11d04be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved at sentence 0 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 10 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 20 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 30 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 40 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 50 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 60 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 70 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 80 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 90 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 100 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 110 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 120 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 130 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 140 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 150 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 160 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 170 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 180 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 190 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 200 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 210 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 220 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 230 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 240 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 250 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 260 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 270 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 280 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 290 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 300 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 310 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 320 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 330 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 340 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Checkpoint saved at sentence 350 for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx.\n",
            "Analysis completed for /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Zgodność_s2_twitter_AI.xlsx and saved as /content/drive/MyDrive/MA thesis/Open AI automatic annotation/Pliki do zgodności/Twitter_AI_with_unclear_output.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkRpgvO9blIE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}